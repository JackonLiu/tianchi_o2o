{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     26,
     35,
     39,
     43
    ]
   },
   "outputs": [],
   "source": [
    "###############\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white', context='notebook', palette='deep')  \n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  \n",
    "\n",
    "\n",
    "\n",
    "off_train = pd.read_csv('../data/ccf_offline_stage1_train.csv',header=None)\n",
    "off_train.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "\n",
    "off_test = pd.read_csv('../data/ccf_offline_stage1_test_revised.csv',header=None)\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n",
    "\n",
    "off_train.drop(index=0,inplace=True)\n",
    "off_test.drop(index=0,inplace=True)\n",
    "\n",
    "off_train.fillna('null',inplace=True)\n",
    "\n",
    "def tran_int_str(col):\n",
    "    if col=='null':\n",
    "        return col\n",
    "    else:\n",
    "        return str(int(float(col)))\n",
    "off_train['date'] = off_train['date'].apply(tran_int_str)\n",
    "off_train['date_received'] = off_train['date_received'].apply(tran_int_str)\n",
    "\n",
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.date >= '20160315') & (off_train.date <= '20160630')) | \n",
    "                     ((off_train.date == 'null') & (off_train.date_received >= '20160315') &(off_train.date_received <= '20160630'))]\n",
    "\n",
    "dataset2 = off_train[(off_train.date_received >= '20160515') & (off_train.date_received <= '20160615')]\n",
    "feature2 = off_train[(off_train.date >= '20160201') & (off_train.date <= '20160514')| \n",
    "                     ((off_train.date == 'null') & (off_train.date_received >= '20160201') & (off_train.date_received <= '20160514'))]\n",
    "\n",
    "dataset1 = off_train[(off_train.date_received >= '20160414') & (off_train.date_received <= '20160514')]\n",
    "feature1 = off_train[(off_train.date >= '20160101') & (off_train.date <= '20160413')| \n",
    "                     ((off_train.date == 'null') & (off_train.date_received >= '20160101') & (off_train.date_received <= '20160413'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_other_feather(dataset3):\n",
    "    t = dataset3[['user_id']]\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "    t = t.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    t1 = dataset3[['user_id','coupon_id']]\n",
    "    t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "    t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "    t2 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t2.date_received = t2.date_received.astype('str')\n",
    "    t2 = t2.groupby(['user_id', 'coupon_id'])['date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    t2['receive_number'] = t2.date_received.apply(lambda s: len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number > 1]        #保证至少有两条领取记录,代表一定使用过了上一张优惠券\n",
    "    t2['max_date_received'] = t2.date_received.apply(lambda s: max([int(d) for d in s.split(':')]))\n",
    "    t2['min_date_received'] = t2.date_received.apply(lambda s: min([int(d) for d in s.split(':')]))\n",
    "    t2 = t2[['user_id', 'coupon_id', 'max_date_received', 'min_date_received']]\n",
    "\n",
    "    t3 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t3 = pd.merge(t3, t2, on=['user_id', 'coupon_id'], how='left')\n",
    "    t3.date_received = t3.date_received.apply(lambda x : float(x))\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] = t3.max_date_received - t3.date_received\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received - t3.min_date_received\n",
    "    def is_firstlastone(x):\n",
    "        if x == 0:\n",
    "            return 1\n",
    "        elif x > 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1  #those only receive once\n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "    t3 = t3[['user_id', 'coupon_id', 'date_received','this_month_user_receive_same_coupon_lastone',\n",
    "             'this_month_user_receive_same_coupon_firstone']]\n",
    "    t3['date_received'] = t3['date_received'].apply(lambda x : str(int(x)))   #将t3的时间格式转换为str\n",
    "\n",
    "\n",
    "    t4 = dataset3[['user_id','date_received']]\n",
    "    t4['this_day_user_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "    t5 = dataset3[['user_id','coupon_id','date_received']]\n",
    "    t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "    t6 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t6.date_received = t6.date_received.astype('str')\n",
    "    t6 = t6.groupby(['user_id', 'coupon_id'])['date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    t6.rename(columns={'date_received': 'dates'}, inplace=True)\n",
    "    def get_day_gap_before(s):\n",
    "        date_received, dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(date_received[0:4]), int(date_received[4:6]), int(date_received[6:8])) - \n",
    "                        date(int(d[0:4]), int(d[4:6]), int(d[6:8]))).days\n",
    "            if this_gap > 0:                   #只考虑以前领取的\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    def get_day_gap_after(s):\n",
    "        date_received, dates = s.split('-')\n",
    "        dates = dates.split(':')\n",
    "        gaps = []\n",
    "        for d in dates:\n",
    "            this_gap = (date(int(d[0:4]), int(d[4:6]), int(d[6:8])) - \n",
    "                        date(int(date_received[0:4]), int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "            if this_gap > 0:                    #只考虑之后领取的\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    t7 = dataset3[['user_id', 'coupon_id', 'date_received']]\n",
    "    t7 = pd.merge(t7, t6, on=['user_id', 'coupon_id'], how='left')\n",
    "    t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "    t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[['user_id', 'coupon_id', 'date_received', 'day_gap_before', 'day_gap_after']]\n",
    "\n",
    "    other_feature3 = pd.merge(t1, t, on='user_id')\n",
    "    other_feature3 = pd.merge(other_feature3, t3, on=['user_id', 'coupon_id'])\n",
    "    other_feature3 = pd.merge(other_feature3, t4, on=['user_id', 'date_received'])\n",
    "    other_feature3 = pd.merge(other_feature3, t5, on=['user_id', 'coupon_id', 'date_received'])\n",
    "    # other_feature3 = pd.merge(other_feature3, t7, on=['user_id', 'coupon_id', 'date_received'])\n",
    "    \n",
    "    return other_feature3\n",
    "\n",
    "other_feature3 = get_other_feather(dataset3)\n",
    "other_feature3.to_csv('../data/other_feature3.csv', index=None)\n",
    "\n",
    "other_feature2 = get_other_feather(dataset2)\n",
    "other_feature2.to_csv('../data/other_feature2.csv', index=None)\n",
    "\n",
    "other_feature1 = get_other_feather(dataset1)\n",
    "other_feature1.to_csv('../data/other_feature1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137167, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feature1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优惠券特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     7,
     14,
     21,
     29
    ]
   },
   "outputs": [],
   "source": [
    "def calc_discount_rate(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return float(s[0])\n",
    "    else:\n",
    "        return 1.0-float(s[1])/float(s[0])\n",
    "def get_discount_man(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "def get_discount_jian(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "def is_man_jian(s):\n",
    "    s =str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_coupon_feather(dataset3):\n",
    "    #dataset3\n",
    "    dataset3['day_of_week'] = dataset3.date_received.astype('str').apply(lambda x: date(int(x[0:4]), int(x[4:6]), int(x[6:8])).weekday() + 1)\n",
    "    dataset3['day_of_month'] = dataset3.date_received.astype('str').apply(lambda x: int(x[6:8]))\n",
    "    dataset3['days_distance'] = dataset3.date_received.astype('str').apply(lambda x: (date(int(x[0:4]), int(x[4:6]), int(x[6:8])) - date(2016, 6, 30)).days)\n",
    "    dataset3['discount_man'] = dataset3.discount_rate.apply(get_discount_man)\n",
    "    dataset3['discount_jian'] = dataset3.discount_rate.apply(get_discount_jian)\n",
    "    dataset3['is_man_jian'] = dataset3.discount_rate.apply(is_man_jian)\n",
    "    dataset3['discount_rate'] = dataset3.discount_rate.apply(calc_discount_rate)\n",
    "    #先提取出统计特征（小数据集），然后合并到原来的大数据集\n",
    "    d = dataset3[['coupon_id']]\n",
    "    d['coupon_count'] = 1\n",
    "    d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "    dataset3 = pd.merge(dataset3, d, on='coupon_id', how='left')\n",
    "    \n",
    "    return dataset3\n",
    "\n",
    "dataset3 = get_coupon_feather(dataset3)\n",
    "dataset3.to_csv('../data/coupon3_feature.csv', index=None)\n",
    "\n",
    "dataset2 = get_coupon_feather(dataset2)\n",
    "dataset2.to_csv('../data/coupon2_feature.csv', index=None)\n",
    "\n",
    "dataset1 = get_coupon_feather(dataset1)\n",
    "dataset1.to_csv('../data/coupon1_feature.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113640, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 商家相关特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#for dataset3\n",
    "def get_merchant_feather(feature3):\n",
    "    merchant3 = feature3[['merchant_id', 'coupon_id', 'distance', 'date_received', 'date']]\n",
    "    t = merchant3[['merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    #每商家总消费记录数目\n",
    "    t1 = merchant3[merchant3.date != 'null'][['merchant_id']]\n",
    "    t1['total_sales'] = 1\n",
    "    t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #商家优惠券使用记录\n",
    "    t2 = merchant3[(merchant3.date != 'null') & (merchant3.coupon_id != 'null')][['merchant_id']]\n",
    "    t2['sales_use_coupon'] = 1\n",
    "    t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #每家店发出多少优惠券\n",
    "    t3 = merchant3[merchant3.coupon_id != 'null'][['merchant_id']]\n",
    "    t3['total_coupon'] = 1\n",
    "    t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #商家被核销优惠券中的平均/最小/最大/中位数用户-商家距离\n",
    "    t4 = merchant3[(merchant3.date != 'null') & (merchant3.coupon_id != 'null')][['merchant_id', 'distance']]\n",
    "    t4.replace('null', -1, inplace=True)\n",
    "    t4.distance = t4.distance.astype('int')\n",
    "    t4.replace(-1, np.nan, inplace=True)\n",
    "    t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "    t5.rename(columns={'distance': 'merchant_min_distance'}, inplace=True)\n",
    "\n",
    "    t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "    t6.rename(columns={'distance': 'merchant_max_distance'}, inplace=True)\n",
    "\n",
    "    t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "    t7.rename(columns={'distance': 'merchant_mean_distance'}, inplace=True)\n",
    "\n",
    "    t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "    t8.rename(columns={'distance': 'merchant_median_distance'}, inplace=True)\n",
    "\n",
    "    merchant3_feature = pd.merge(t, t1, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t2, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t3, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t5, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t6, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t7, on='merchant_id', how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature, t8, on='merchant_id', how='left')\n",
    "    merchant3_feature.sales_use_coupon = merchant3_feature.sales_use_coupon.replace(np.nan, 0)  #fillna with 0\n",
    "\n",
    "    #商家优惠券核销率\n",
    "    merchant3_feature[ 'merchant_coupon_transfer_rate'] = merchant3_feature.sales_use_coupon.astype( 'float') / merchant3_feature.total_coupon\n",
    "\n",
    "    #商家销售中使用优惠券概率\n",
    "    merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "\n",
    "    merchant3_feature.total_coupon = merchant3_feature.total_coupon.replace(np.nan, 0)  #fillna with 0\n",
    "    \n",
    "    \n",
    "    return merchant3_feature\n",
    "\n",
    "merchant3_feature = get_merchant_feather(feature3)\n",
    "merchant3_feature.to_csv('../data/merchant3_feature.csv', index=None)\n",
    "\n",
    "merchant2_feature = get_merchant_feather(feature2)\n",
    "merchant2_feature.to_csv('../data/merchant2_feature.csv', index=None)\n",
    "\n",
    "merchant1_feature = get_merchant_feather(feature1)\n",
    "merchant1_feature.to_csv('../data/merchant1_feature.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7937, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant1_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户线下特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1,
     2
    ]
   },
   "outputs": [],
   "source": [
    "#for dataset3\n",
    "def user_off_feather(feature3):\n",
    "    def get_user_date_datereceived_gap(s):\n",
    "        s = s.split(':')\n",
    "        return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "    user3 = feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "    t = user3[['user_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    #消费者消费店家数目\n",
    "    t1 = user3[user3.date!='null'][['user_id','merchant_id']]\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "    t1.merchant_id = 1\n",
    "    t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "    t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "    #消费者领取优惠券最近/最远/平均/中位数距离\n",
    "    t2 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id','distance']]\n",
    "    t2.replace('null',-1,inplace=True)\n",
    "    t2.distance = t2.distance.astype('int')\n",
    "    t2.replace(-1,np.nan,inplace=True)\n",
    "    t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "    t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "    t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "    t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "    t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "    t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "    t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "    t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "    #消费者使用优惠券购买总次数\n",
    "    t7 = user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id']]\n",
    "    t7['buy_use_coupon'] = 1\n",
    "    t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #消费者消费总次数\n",
    "    t8 = user3[user3.date!='null'][['user_id']]\n",
    "    t8['buy_total'] = 1\n",
    "    t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "    #每个消费者共领取多少优惠券\n",
    "    t9 = user3[user3.coupon_id!='null'][['user_id']]\n",
    "    t9['coupon_received'] = 1\n",
    "    t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "    #消费者领取优惠券到使用优惠券时间差\n",
    "    t10 = user3[(user3.date_received!='null')&(user3.date!='null')][['user_id','date_received','date']]\n",
    "    t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "    t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "    t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "    #消费者领取优惠券到使用优惠券平均/最大/最小/中位数时间差\n",
    "    t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "    t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "    t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "    t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "    t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "    t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "\n",
    "    #合并列表\n",
    "    user3_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t3,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t4,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t5,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t6,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t7,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t8,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t9,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t11,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t12,on='user_id',how='left')\n",
    "    user3_feature = pd.merge(user3_feature,t13,on='user_id',how='left')\n",
    "    user3_feature.count_merchant = user3_feature.count_merchant.replace(np.nan,0)\n",
    "    user3_feature.buy_use_coupon = user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "    #消费者使用优惠券频率\n",
    "    user3_feature['buy_use_coupon_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.buy_total.astype('float')\n",
    "    #消费者优惠券转化率\n",
    "    user3_feature['user_coupon_transfer_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.coupon_received.astype('float')\n",
    "    user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)\n",
    "    user3_feature.coupon_received = user3_feature.coupon_received.replace(np.nan,0)\n",
    "    \n",
    "    return user3_feature\n",
    "    \n",
    "user3_feature = user_off_feather(feature3)\n",
    "user3_feature.to_csv('../data/user3_feature.csv',index=None)\n",
    "\n",
    "user2_feature = user_off_feather(feature2)\n",
    "user2_feature.to_csv('../data/user2_feature.csv',index=None)\n",
    "\n",
    "user1_feature = user_off_feather(feature1)\n",
    "user1_feature.to_csv('../data/user1_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382698, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户商家交互特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#for dataset3\n",
    "def user_merchant_feature(feature3):\n",
    "    all_user_merchant = feature3[['user_id','merchant_id']]\n",
    "    all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户在该商家消费总计\n",
    "    t = feature3[['user_id','merchant_id','date']]\n",
    "    t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "    t['user_merchant_buy_total'] = 1\n",
    "    t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户领取该商家优惠券总计\n",
    "    t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "    t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "    t1['user_merchant_received'] = 1\n",
    "    t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户于该商家使用其优惠券总计\n",
    "    t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "    t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "    t2['user_merchant_buy_use_coupon'] = 1\n",
    "    t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t2.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户于该商家相关记录（优惠券领取，单纯消费等）总计\n",
    "    t3 = feature3[['user_id','merchant_id']]\n",
    "    t3['user_merchant_any'] = 1\n",
    "    t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t3.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用户于该商家单纯消费总计\n",
    "    t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "    t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "    t4['user_merchant_buy_common'] = 1\n",
    "    t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    t4.drop_duplicates(inplace=True)\n",
    "\n",
    "    #merge dataframe\n",
    "    user_merchant3 = pd.merge(all_user_merchant, t, on=['user_id', 'merchant_id'], how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3, t1, on=['user_id', 'merchant_id'], how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3, t2, on=['user_id', 'merchant_id'], how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3, t3, on=['user_id', 'merchant_id'], how='left')\n",
    "    user_merchant3 = pd.merge(user_merchant3, t4, on=['user_id', 'merchant_id'], how='left')\n",
    "    user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan, 0)\n",
    "    user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan, 0)\n",
    "\n",
    "    #用户领取优惠券后转化率（对于仅有一次优惠券记录的用户来说，是否会导致过拟合？）\n",
    "    user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / \\\n",
    "                                                                user_merchant3.user_merchant_received.astype('float')\n",
    "\n",
    "    #用户于该商家购买中使用优惠券比率\n",
    "    user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / \\\n",
    "                                                            user_merchant3.user_merchant_buy_total.astype('float')\n",
    "\n",
    "    #用户与该商家相关记录中购买记录比率\n",
    "    user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / \\\n",
    "                                                user_merchant3.user_merchant_any.astype('float')\n",
    "\n",
    "    #用户与在该商家消费中单纯购买比率\n",
    "    user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / \\\n",
    "                                                            user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    \n",
    "    return user_merchant3\n",
    "\n",
    "user_merchant3 = user_merchant_feature(feature3)\n",
    "user_merchant3.to_csv('../data/user_merchant3.csv', index=None)\n",
    "\n",
    "user_merchant2 = user_merchant_feature(feature2)\n",
    "user_merchant2.to_csv('../data/user_merchant2.csv', index=None)\n",
    "\n",
    "user_merchant1 = user_merchant_feature(feature1)\n",
    "user_merchant1.to_csv('../data/user_merchant1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629500, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_merchant1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练集、验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white', context='notebook', palette='deep')  \n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222261, 50)\n",
      "(492696, 51)\n",
      "(255225, 51)\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0]=='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "coupon3 = pd.read_csv('../data/coupon3_feature.csv')\n",
    "merchant3 = pd.read_csv('../data/merchant3_feature.csv')\n",
    "user3 = pd.read_csv('../data/user3_feature.csv')\n",
    "user_merchant3 = pd.read_csv('../data/user_merchant3.csv')\n",
    "other_feature3 = pd.read_csv('../data/other_feature3.csv')\n",
    "dataset3 = pd.merge(coupon3, merchant3, on='merchant_id', how='left')\n",
    "dataset3 = pd.merge(dataset3, user3, on='user_id', how='left')\n",
    "dataset3 = pd.merge(dataset3, user_merchant3, on=['user_id', 'merchant_id'], how='left')\n",
    "dataset3 = pd.merge(dataset3,other_feature3,on=['user_id', 'coupon_id', 'date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "print(dataset3.shape)\n",
    "dataset3.user_merchant_buy_total = dataset3.user_merchant_buy_total.replace(np.nan, 0)\n",
    "dataset3.user_merchant_any = dataset3.user_merchant_any.replace(np.nan, 0)\n",
    "dataset3.user_merchant_received = dataset3.user_merchant_received.replace(np.nan, 0)\n",
    "dataset3['is_weekend'] = dataset3.day_of_week.apply(lambda x: 1 if x in (6, 7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset3.day_of_week)\n",
    "weekday_dummies.columns = ['weekday' + str(i + 1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset3 = pd.concat([dataset3, weekday_dummies], axis=1)\n",
    "dataset3.drop(['merchant_id', 'day_of_week', 'coupon_count'], axis=1, inplace=True)\n",
    "dataset3 = dataset3.replace('null', np.nan)\n",
    "dataset3.to_csv('../data/dataset3.csv', index=None)\n",
    "\n",
    "\n",
    "\n",
    "coupon2 = pd.read_csv('../data/coupon2_feature.csv')\n",
    "merchant2 = pd.read_csv('../data/merchant2_feature.csv')\n",
    "user2 = pd.read_csv('../data/user2_feature.csv')\n",
    "user_merchant2 = pd.read_csv('../data/user_merchant2.csv')\n",
    "other_feature2 = pd.read_csv('../data/other_feature2.csv')\n",
    "dataset2 = pd.merge(coupon2,merchant2,on='merchant_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user2,on='user_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user_merchant2,on=['user_id','merchant_id'],how='left')\n",
    "dataset2 = pd.merge(dataset2,other_feature2,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "print(dataset2.shape)\n",
    "dataset2.user_merchant_buy_total = dataset2.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset2.user_merchant_any = dataset2.user_merchant_any.replace(np.nan,0)\n",
    "dataset2.user_merchant_received = dataset2.user_merchant_received.replace(np.nan,0)\n",
    "dataset2['is_weekend'] = dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset2.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset2 = pd.concat([dataset2,weekday_dummies],axis=1)\n",
    "dataset2['label'] = dataset2.date.fillna('null').astype('str') + ':' +  dataset2.date_received.astype('str')\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(['merchant_id','day_of_week','date','date_received','coupon_count'],axis=1,inplace=True)\n",
    "dataset2 = dataset2.replace('null',np.nan)\n",
    "dataset2.to_csv('../data/dataset2.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "coupon1 = pd.read_csv('../data/coupon1_feature.csv')\n",
    "merchant1 = pd.read_csv('../data/merchant1_feature.csv')\n",
    "user1 = pd.read_csv('../data/user1_feature.csv')\n",
    "user_merchant1 = pd.read_csv('../data/user_merchant1.csv')\n",
    "other_feature1 = pd.read_csv('../data/other_feature1.csv')\n",
    "dataset1 = pd.merge(coupon1,merchant1,on='merchant_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user1,on='user_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user_merchant1,on=['user_id','merchant_id'],how='left')\n",
    "dataset1 = pd.merge(dataset1,other_feature1,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "print(dataset1.shape)\n",
    "dataset1.user_merchant_buy_total = dataset1.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset1.user_merchant_any = dataset1.user_merchant_any.replace(np.nan,0)\n",
    "dataset1.user_merchant_received = dataset1.user_merchant_received.replace(np.nan,0)\n",
    "dataset1['is_weekend'] = dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset1.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset1 = pd.concat([dataset1,weekday_dummies],axis=1)\n",
    "dataset1['label'] = dataset1.date.fillna('null').astype('str') + ':' +  dataset1.date_received.astype('str')\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(['merchant_id','day_of_week','date','date_received','coupon_count'],axis=1,inplace=True)\n",
    "dataset1 = dataset1.replace('null',np.nan)\n",
    "dataset1.to_csv('../data/dataset1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>days_distance</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>is_man_jian</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>...</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>weekday1</th>\n",
       "      <th>weekday2</th>\n",
       "      <th>weekday3</th>\n",
       "      <th>weekday4</th>\n",
       "      <th>weekday5</th>\n",
       "      <th>weekday6</th>\n",
       "      <th>weekday7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1832624</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>-62</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1832624</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>-62</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13990.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163606</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21</td>\n",
       "      <td>-70</td>\n",
       "      <td>200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163606</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21</td>\n",
       "      <td>-70</td>\n",
       "      <td>200.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4061024</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26</td>\n",
       "      <td>-65</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  coupon_id  discount_rate  distance  day_of_month  days_distance  \\\n",
       "0  1832624     7610.0           0.90       0.0            29            -62   \n",
       "1  1832624     7610.0           0.90       0.0            29            -62   \n",
       "2   163606     5054.0           0.85      10.0            21            -70   \n",
       "3   163606     5054.0           0.85      10.0            21            -70   \n",
       "4  4061024     7610.0           0.90      10.0            26            -65   \n",
       "\n",
       "   discount_man  discount_jian  is_man_jian  total_sales  ...    \\\n",
       "0         200.0           20.0            1        972.0  ...     \n",
       "1         200.0           20.0            1      13990.0  ...     \n",
       "2         200.0           30.0            1         50.0  ...     \n",
       "3         200.0           30.0            1        737.0  ...     \n",
       "4         200.0           20.0            1        972.0  ...     \n",
       "\n",
       "   this_day_user_receive_same_coupon_count  is_weekend  weekday1  weekday2  \\\n",
       "0                                        1           0         0         0   \n",
       "1                                        1           0         0         0   \n",
       "2                                        1           0         0         0   \n",
       "3                                        1           0         0         0   \n",
       "4                                        1           0         0         1   \n",
       "\n",
       "   weekday3  weekday4  weekday5  weekday6  weekday7  label  \n",
       "0         0         0         1         0         0      0  \n",
       "1         0         0         1         0         0      0  \n",
       "2         0         1         0         0         0      0  \n",
       "3         0         1         0         0         0      0  \n",
       "4         0         0         0         0         0      0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>days_distance</th>\n",
       "      <th>discount_man</th>\n",
       "      <th>discount_jian</th>\n",
       "      <th>is_man_jian</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>...</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>weekday1</th>\n",
       "      <th>weekday2</th>\n",
       "      <th>weekday3</th>\n",
       "      <th>weekday4</th>\n",
       "      <th>weekday5</th>\n",
       "      <th>weekday6</th>\n",
       "      <th>weekday7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>-33</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>-33</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>594.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-17</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-45</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  coupon_id  discount_rate  distance  day_of_month  days_distance  \\\n",
       "0  1439408    11002.0       0.866667       1.0            28            -33   \n",
       "1  1439408    11002.0       0.866667       1.0            28            -33   \n",
       "2  1439408     8591.0       0.950000       0.0            13            -17   \n",
       "3  1439408     8591.0       0.950000       0.0            13            -17   \n",
       "4  1439408     8591.0       0.950000       0.0            16            -45   \n",
       "\n",
       "   discount_man  discount_jian  is_man_jian  total_sales  ...    \\\n",
       "0         150.0           20.0            1         63.0  ...     \n",
       "1         150.0           20.0            1        594.0  ...     \n",
       "2          20.0            1.0            1          1.0  ...     \n",
       "3          20.0            1.0            1         13.0  ...     \n",
       "4          20.0            1.0            1          1.0  ...     \n",
       "\n",
       "   this_day_user_receive_same_coupon_count  is_weekend  weekday1  weekday2  \\\n",
       "0                                        1           1         0         0   \n",
       "1                                        1           1         0         0   \n",
       "2                                        1           0         1         0   \n",
       "3                                        1           0         1         0   \n",
       "4                                        1           0         1         0   \n",
       "\n",
       "   weekday3  weekday4  weekday5  weekday6  weekday7  label  \n",
       "0         0         0         0         1         0      0  \n",
       "1         0         0         0         1         0      0  \n",
       "2         0         0         0         0         0      0  \n",
       "3         0         0         0         0         0      0  \n",
       "4         0         0         0         0         0     -1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgb模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     35
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251818, 52) (483596, 52) (222261, 52)\n",
      "[0]\ttrain-auc:0.829958\n",
      "[1]\ttrain-auc:0.835059\n",
      "[2]\ttrain-auc:0.844135\n",
      "[3]\ttrain-auc:0.844723\n",
      "[4]\ttrain-auc:0.844425\n",
      "[5]\ttrain-auc:0.844614\n",
      "[6]\ttrain-auc:0.845563\n",
      "[7]\ttrain-auc:0.845202\n",
      "[8]\ttrain-auc:0.845547\n",
      "[9]\ttrain-auc:0.84775\n",
      "            user_id      coupon_id  date_received          label\n",
      "count  2.222610e+05  222261.000000   2.222610e+05  222261.000000\n",
      "mean   3.684147e+06    9092.765946   2.016072e+07       0.348270\n",
      "std    2.126266e+06    4144.899212   9.022204e+00       0.216230\n",
      "min    2.090000e+02       3.000000   2.016070e+07       0.000000\n",
      "25%    1.843454e+06    5143.000000   2.016071e+07       0.230149\n",
      "50%    3.681845e+06    9983.000000   2.016072e+07       0.263557\n",
      "75%    5.523459e+06   13602.000000   2.016072e+07       0.393458\n",
      "max    7.361024e+06   14045.000000   2.016073e+07       1.000000\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset1 = pd.read_csv('../data/dataset1.csv')\n",
    "dataset1.label.replace(-1,0,inplace=True)\n",
    "\n",
    "dataset2 = pd.read_csv('../data/dataset2.csv')\n",
    "dataset2.label.replace(-1,0,inplace=True)\n",
    "\n",
    "dataset3 = pd.read_csv('../data/dataset3.csv')\n",
    "\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "\n",
    "dataset12 = pd.concat([dataset1,dataset2],axis=0)\n",
    "\n",
    "dataset1_y = dataset1.label\n",
    "dataset1_x = dataset1.drop(['user_id','label'],axis=1)  # 'day_gap_before','day_gap_after' cause overfitting, 0.77\n",
    "dataset2_y = dataset2.label\n",
    "dataset2_x = dataset2.drop(['user_id','label'],axis=1)\n",
    "dataset12_y = dataset12.label\n",
    "dataset12_x = dataset12.drop(['user_id','label'],axis=1)\n",
    "dataset3_preds = dataset3[['user_id','coupon_id','date_received']]\n",
    "dataset3_x = dataset3.drop(['user_id','coupon_id','date_received'],axis=1)\n",
    "\n",
    "print (dataset1_x.shape, dataset2_x.shape, dataset3_x.shape)\n",
    "\n",
    "dataset1 = xgb.DMatrix(dataset1_x,label=dataset1_y)\n",
    "dataset2 = xgb.DMatrix(dataset2_x,label=dataset2_y)\n",
    "dataset12 = xgb.DMatrix(dataset12_x,label=dataset12_y)\n",
    "dataset3 = xgb.DMatrix(dataset3_x)\n",
    "\n",
    "params={'booster':'gbtree',\n",
    "\t    'objective': 'rank:pairwise',\n",
    "\t    'eval_metric':'auc',\n",
    "\t    'gamma':0.1,\n",
    "\t    'min_child_weight':1.1,\n",
    "\t    'max_depth':5,\n",
    "\t    'lambda':10,\n",
    "\t    'subsample':0.7,\n",
    "\t    'colsample_bytree':0.7,\n",
    "\t    'colsample_bylevel':0.7,\n",
    "\t    'eta': 0.01,\n",
    "\t    'tree_method':'exact',\n",
    "\t    'seed':0,\n",
    "\t    'nthread':12\n",
    "\t    }\n",
    "\n",
    "#train on dataset1, evaluate on dataset2\n",
    "#watchlist = [(dataset1,'train'),(dataset2,'val')]\n",
    "#model = xgb.train(params,dataset1,num_boost_round=3000,evals=watchlist,early_stopping_rounds=300)\n",
    "\n",
    "watchlist = [(dataset12,'train')]\n",
    "model = xgb.train(params,dataset12,num_boost_round=10,evals=watchlist)\n",
    "\n",
    "#predict test set\n",
    "dataset3_preds['label'] = model.predict(dataset3)\n",
    "dataset3_preds.label = MinMaxScaler().fit_transform(np.array(dataset3_preds.label).reshape(-1, 1))\n",
    "dataset3_preds.sort_values(by=['coupon_id','label'],inplace=True)\n",
    "dataset3_preds.to_csv(\"xgb_preds.csv\",index=None,header=None)\n",
    "print (dataset3_preds.describe())\n",
    "    \n",
    "#save feature score\n",
    "feature_score = model.get_fscore()\n",
    "feature_score = sorted(feature_score.items(), key=lambda x:x[1],reverse=True)\n",
    "fs = []\n",
    "for (key,value) in feature_score:\n",
    "    fs.append(\"{0},{1}\\n\".format(key,value))\n",
    "    \n",
    "with open('xgb_feature_score.csv','w') as f:\n",
    "    f.writelines(\"feature,score\\n\")\n",
    "    f.writelines(fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
