{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###库#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from time import time\n",
    "import random\n",
    "import re\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  #'all'|'last'|'last_expr'|'none'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from function import feat_count, feat_max, feat_mean, feat_min, feat_mode, feat_nunique, feat_sum\n",
    "from function import RFECV_feature_sel, Tree_feature_sel\n",
    "\n",
    "input_path = '../input/'\n",
    "submi_path = '../submision/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train: (11429826, 7)\n",
      "off_train: (1754884, 7)\n",
      "off_test: (113640, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Action</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13740231</td>\n",
       "      <td>18907</td>\n",
       "      <td>2</td>\n",
       "      <td>100017492</td>\n",
       "      <td>500:50</td>\n",
       "      <td>20160513</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13740231</td>\n",
       "      <td>34805</td>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>20160321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Action  Coupon_id Discount_rate Date_received  \\\n",
       "0  13740231        18907       2  100017492        500:50      20160513   \n",
       "1  13740231        34805       1       null          null          null   \n",
       "\n",
       "       Date  \n",
       "0      null  \n",
       "1  20160321  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1</td>\n",
       "      <td>20160528</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id Coupon_id Discount_rate Distance Date_received  \\\n",
       "0  1439408         2632      null          null        0          null   \n",
       "1  1439408         4663     11002        150:20        1      20160528   \n",
       "\n",
       "       Date  \n",
       "0  20160217  \n",
       "1      null  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4129537</td>\n",
       "      <td>450</td>\n",
       "      <td>9983</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1</td>\n",
       "      <td>20160712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6949378</td>\n",
       "      <td>1300</td>\n",
       "      <td>3429</td>\n",
       "      <td>30:5</td>\n",
       "      <td>null</td>\n",
       "      <td>20160706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate Distance  Date_received\n",
       "0  4129537          450       9983          30:5        1       20160712\n",
       "1  6949378         1300       3429          30:5     null       20160706"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "on_train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11429826 entries, 0 to 11429825\n",
      "Data columns (total 7 columns):\n",
      "User_id          int64\n",
      "Merchant_id      int64\n",
      "Action           int64\n",
      "Coupon_id        object\n",
      "Discount_rate    object\n",
      "Date_received    object\n",
      "Date             object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 610.4+ MB\n",
      "\n",
      "\n",
      "off_train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754884 entries, 0 to 1754883\n",
      "Data columns (total 7 columns):\n",
      "User_id          int64\n",
      "Merchant_id      int64\n",
      "Coupon_id        object\n",
      "Discount_rate    object\n",
      "Distance         object\n",
      "Date_received    object\n",
      "Date             object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 93.7+ MB\n",
      "\n",
      "\n",
      "off_test:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113640 entries, 0 to 113639\n",
      "Data columns (total 6 columns):\n",
      "User_id          113640 non-null int64\n",
      "Merchant_id      113640 non-null int64\n",
      "Coupon_id        113640 non-null int64\n",
      "Discount_rate    113640 non-null object\n",
      "Distance         113640 non-null object\n",
      "Date_received    113640 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# 结论：\n",
    "# 线上数据量：千万级\n",
    "# 线下数据量：百万级\n",
    "# 存在较多的空值，空值有业务关系\n",
    "\n",
    "on_train = pd.read_csv(input_path + 'ccf_online_stage1_train.csv')\n",
    "off_train = pd.read_csv(input_path + 'ccf_offline_stage1_train.csv')\n",
    "off_test = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')\n",
    "\n",
    "on_train = on_train.fillna(-1)\n",
    "off_train = off_train.fillna(-1)\n",
    "off_test = off_test.fillna(-1)\n",
    "\n",
    "\n",
    "print('on_train:', on_train.shape)\n",
    "print('off_train:', off_train.shape)\n",
    "print('off_test:', off_test.shape)\n",
    "\n",
    "on_train.head(2)\n",
    "off_train.head(2)\n",
    "off_test.head(2)\n",
    "\n",
    "print('\\n')\n",
    "print('on_train:')\n",
    "on_train.info()\n",
    "\n",
    "print('\\n')\n",
    "print('off_train:')\n",
    "off_train.info()\n",
    "\n",
    "print('\\n')\n",
    "print('off_test:')\n",
    "off_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['null', '150:20', '20:1', '200:20', '30:5', '50:10', '10:5',\n",
       "       '100:10', '200:30', '20:5', '30:10', '50:5', '150:10', '100:30',\n",
       "       '200:50', '100:50', '300:30', '50:20', '0.9', '10:1', '30:1',\n",
       "       '0.95', '100:5', '5:1', '100:20', '0.8', '50:1', '200:10',\n",
       "       '300:20', '100:1', '150:30', '300:50', '20:10', '0.85', '0.6',\n",
       "       '150:50', '0.75', '0.5', '200:5', '0.7', '30:20', '300:10', '0.2',\n",
       "       '50:30', '200:100', '150:5'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '1', 'null', '2', '10', '4', '7', '9', '3', '5', '6', '8'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毫无疑问，基本上都是“满多少，减多少”的优惠券\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21906574f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD8CAYAAABZ/vJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看看哪些优惠券是经常被领的\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>701602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30:5</td>\n",
       "      <td>270712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100:10</td>\n",
       "      <td>182554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200:20</td>\n",
       "      <td>111046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:5</td>\n",
       "      <td>91013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20:1</td>\n",
       "      <td>51705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50:5</td>\n",
       "      <td>47379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100:30</td>\n",
       "      <td>38196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200:30</td>\n",
       "      <td>29327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300:30</td>\n",
       "      <td>28979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50:10</td>\n",
       "      <td>28452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10:5</td>\n",
       "      <td>25925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.95</td>\n",
       "      <td>20568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10:1</td>\n",
       "      <td>17842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30:1</td>\n",
       "      <td>17654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1\n",
       "0     null  701602\n",
       "1     30:5  270712\n",
       "2   100:10  182554\n",
       "3   200:20  111046\n",
       "4     20:5   91013\n",
       "5     20:1   51705\n",
       "6     50:5   47379\n",
       "7   100:30   38196\n",
       "8   200:30   29327\n",
       "9   300:30   28979\n",
       "10   50:10   28452\n",
       "11    10:5   25925\n",
       "12    0.95   20568\n",
       "13    10:1   17842\n",
       "14    30:1   17654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x219000f40f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD8CAYAAABZ/vJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看看哪些优惠券是经常被领的\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>701602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30:5</td>\n",
       "      <td>270712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100:10</td>\n",
       "      <td>182554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200:20</td>\n",
       "      <td>111046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:5</td>\n",
       "      <td>91013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20:1</td>\n",
       "      <td>51705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50:5</td>\n",
       "      <td>47379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100:30</td>\n",
       "      <td>38196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200:30</td>\n",
       "      <td>29327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300:30</td>\n",
       "      <td>28979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50:10</td>\n",
       "      <td>28452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10:5</td>\n",
       "      <td>25925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.95</td>\n",
       "      <td>20568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10:1</td>\n",
       "      <td>17842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30:1</td>\n",
       "      <td>17654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1\n",
       "0     null  701602\n",
       "1     30:5  270712\n",
       "2   100:10  182554\n",
       "3   200:20  111046\n",
       "4     20:5   91013\n",
       "5     20:1   51705\n",
       "6     50:5   47379\n",
       "7   100:30   38196\n",
       "8   200:30   29327\n",
       "9   300:30   28979\n",
       "10   50:10   28452\n",
       "11    10:5   25925\n",
       "12    0.95   20568\n",
       "13    10:1   17842\n",
       "14    30:1   17654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结论：\n",
    "# 有“满减”和“折扣”优惠券两种\n",
    "# 小额的‘满减’优惠券经常被领取\n",
    "# 折扣优惠券被领取并且核销的比例大\n",
    "\n",
    "###优惠券和距离\n",
    "off_train.Discount_rate.unique()\n",
    "off_train.Distance.unique()\n",
    "\n",
    "print('毫无疑问，基本上都是“满多少，减多少”的优惠券')\n",
    "\n",
    "#每种类型消费券出现的次数\n",
    "X = []\n",
    "Y = []\n",
    "for rate_type in (off_train.Discount_rate.unique()):\n",
    "    if rate_type != -1:\n",
    "        x = rate_type\n",
    "        y = off_train[off_train.Discount_rate == rate_type].Discount_rate.count()\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "df_tem = pd.DataFrame([X, Y]).T\n",
    "df_tem = df_tem.sort_values(by=1, ascending = False).reset_index(drop=True)\n",
    "\n",
    "df_tem[1].plot()\n",
    "plt.show()\n",
    "\n",
    "print('看看哪些优惠券是经常被领的')\n",
    "df_tem.shape\n",
    "df_tem.head(15)\n",
    "\n",
    "\n",
    "##优惠券核销的次数\n",
    "X = []\n",
    "Y = []\n",
    "for rate_type in (off_train.Discount_rate.unique()):\n",
    "    if rate_type != -1:\n",
    "        x = rate_type\n",
    "        y = off_train[(off_train.Discount_rate == rate_type) & (off_train.Date != -1)].Discount_rate.count()\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "df_tem = pd.DataFrame([X, Y]).T\n",
    "df_tem = df_tem.sort_values(by=1, ascending = False).reset_index(drop=True)\n",
    "\n",
    "df_tem[1].plot()\n",
    "plt.show()\n",
    "\n",
    "print('看看哪些优惠券是经常被领的')\n",
    "df_tem.shape\n",
    "df_tem.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>20160214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>20160607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>20160129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>20160130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>20160125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id Date_received  count\n",
       "0        4      20160214      1\n",
       "1        4      20160607      1\n",
       "2       35      20160129      2\n",
       "3       35      20160130      2\n",
       "4       36      20160125      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>null</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>null</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>null</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>null</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>null</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Date  count\n",
       "0        4  null      2\n",
       "1       35  null      4\n",
       "2       36  null      2\n",
       "3       64  null      1\n",
       "4      110  null      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结论：\n",
    "# 一天可以领劵很多次，但一般只消费一次\n",
    "\n",
    "coupon_byDate = off_train[off_train['Date_received'] != -1].groupby(['User_id', 'Date_received'], as_index=False)[['Merchant_id']].count()\n",
    "coupon_byDate.columns = ['User_id', 'Date_received','count']\n",
    "\n",
    "buy_byDate = off_train[(off_train['Date'] != -1) & (off_train['Date_received'] != -1)].groupby(['User_id', 'Date'], as_index=False)[['Merchant_id']].count()\n",
    "buy_byDate.columns = ['User_id', 'Date','count']\n",
    "\n",
    "coupon_byDate.head()\n",
    "buy_byDate.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户： 2\n",
      "商店： 1\n",
      "优惠券： 2050\n",
      "\n",
      "\n",
      "测试集上的数据，基本train上都有覆盖\n"
     ]
    }
   ],
   "source": [
    "# 测试集中出现，但训练集没出现\n",
    "\n",
    "print('用户：', len(set(off_test.User_id) - set(off_train.User_id)))\n",
    "print('商店：', len(set(off_test.Merchant_id) - set(off_train.Merchant_id)))\n",
    "print('优惠券：', len(set(off_test.Coupon_id) - set(off_train.Coupon_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('测试集上的数据，基本train上都有覆盖')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1754884, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结论：\n",
    "# 正负样本大约1:10\n",
    "\n",
    "###正样本\n",
    "posi_sample_offLine = off_train[(off_train.Coupon_id != -1) & (off_train.Date != -1)]\n",
    "posi_sample_offLine.shape\n",
    "\n",
    "###负样本\n",
    "navi_sample_offLine = off_train[(off_train.Coupon_id != -1) & (off_train.Date == -1)]\n",
    "navi_sample_offLine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "online训练集，领取优惠券的最早时期： 20160102\n",
      "online训练集，领取优惠券的最后时期： null\n",
      "\n",
      "\n",
      "offline训练集，领取优惠券的最早时期： 20160102\n",
      "offline训练集，领取优惠券的最后时期： null\n",
      "\n",
      "\n",
      "online训练集，消费的最早时期： 20160102\n",
      "online训练集，消费的最后时期： null\n",
      "\n",
      "\n",
      "offline训练集，消费的最早时期： 20160102\n",
      "offline训练集，消费的最后时期： null\n",
      "\n",
      "\n",
      "offline测试集，领取优惠券的最早时期： 20160701\n",
      "offline测试集，领取优惠券的最后时期： 20160731\n"
     ]
    }
   ],
   "source": [
    "tem = sorted(on_train.Date_received.unique())\n",
    "print('online训练集，领取优惠券的最早时期：', tem[1])\n",
    "print('online训练集，领取优惠券的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_train.Date_received.unique())\n",
    "print('offline训练集，领取优惠券的最早时期：', tem[1])\n",
    "print('offline训练集，领取优惠券的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(on_train.Date.unique())\n",
    "print('online训练集，消费的最早时期：', tem[1])\n",
    "print('online训练集，消费的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_train.Date.unique())\n",
    "print('offline训练集，消费的最早时期：', tem[1])\n",
    "print('offline训练集，消费的最后时期：', tem[-1])\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "tem = sorted(off_test.Date_received.unique())\n",
    "print('offline测试集，领取优惠券的最早时期：', tem[0])\n",
    "print('offline测试集，领取优惠券的最后时期：', tem[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train:\n",
      "有优惠券， 购买商品： 11429826\n",
      "有优惠券， 没有购买商品： 0\n",
      "无优惠券， 购买商品： 0\n",
      "无优惠券， 没有购买商品： 0\n",
      "\n",
      "\n",
      "off_train:\n",
      "有优惠券， 购买商品： 1754884\n",
      "有优惠券， 没有购买商品： 0\n",
      "无优惠券， 购买商品： 0\n",
      "无优惠券， 没有购买商品： 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 结论：\n",
    "# 领取优化券后，用优惠券购买的人比较少\n",
    "# 只领取，而不购买的人很多\n",
    "# 更多的人是不领优惠券，就直接购买了\n",
    "\n",
    "print('on_train:')\n",
    "print('有优惠券， 购买商品：', on_train[(on_train['Coupon_id'] != -1) & (on_train['Date'] != -1)].shape[0])\n",
    "print('有优惠券， 没有购买商品：', on_train[(on_train['Coupon_id'] != -1) & (on_train['Date'] == -1)].shape[0])\n",
    "print('无优惠券， 购买商品：', on_train[(on_train['Coupon_id'] == -1) & (on_train['Date'] != -1)].shape[0])\n",
    "print('无优惠券， 没有购买商品：', on_train[(on_train['Coupon_id'] == -1) & (on_train['Date'] == -1)].shape[0])\n",
    "print('\\n')\n",
    "\n",
    "print('off_train:')\n",
    "print('有优惠券， 购买商品：', off_train[(off_train['Coupon_id'] != -1) & (off_train['Date'] != -1)].shape[0])\n",
    "print('有优惠券， 没有购买商品：', off_train[(off_train['Coupon_id'] != -1) & (off_train['Date'] == -1)].shape[0])\n",
    "print('无优惠券， 购买商品：', off_train[(off_train['Coupon_id'] == -1) & (off_train['Date'] != -1)].shape[0])\n",
    "print('无优惠券， 没有购买商品：', off_train[(off_train['Coupon_id'] == -1) & (off_train['Date'] == -1)].shape[0])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train的人数： 762858\n",
      "off_train的人数： 539438\n",
      "off_train和on_train的人数交集： 267448\n",
      "\n",
      "\n",
      "on_train的商户数： 7999\n",
      "off_train的商户数： 8415\n",
      "off_train和on_train的商户数交集： 0\n",
      "\n",
      "\n",
      "on_train的优惠券数： 27748\n",
      "off_train的优惠券数： 9739\n",
      "off_train和on_train的优惠券数交集： 1\n",
      "\n",
      "\n",
      "off_test的人数： 76309\n",
      "off_train和off_test的人数交集： 76307\n",
      "\n",
      "\n",
      "on_train的优惠券数： 27748\n",
      "off_train的优惠券数： 9739\n",
      "off_train领取优惠券的记录数： 1754884\n",
      "off_test的优惠券数： 2050\n",
      "off_test领取优惠券的记录数： 113640\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# 结论：\n",
    "\n",
    "\n",
    "print('on_train的人数：', len(set(on_train.User_id)))\n",
    "print('off_train的人数：', len(set(off_train.User_id)))\n",
    "print('off_train和on_train的人数交集：', len(set(on_train.User_id) & set(off_train.User_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的商户数：', len(set(on_train.Merchant_id)))\n",
    "print('off_train的商户数：', len(set(off_train.Merchant_id)))\n",
    "print('off_train和on_train的商户数交集：', len(set(on_train.Merchant_id) & set(off_train.Merchant_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的优惠券数：', len(set(on_train.Coupon_id)))\n",
    "print('off_train的优惠券数：', len(set(off_train.Coupon_id)))\n",
    "print('off_train和on_train的优惠券数交集：', len(set(on_train.Coupon_id) & set(off_train.Coupon_id)))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('off_test的人数：', len(set(off_test.User_id)))\n",
    "print('off_train和off_test的人数交集：', len(set(off_train.User_id) & set(off_test.User_id)))\n",
    "\n",
    "print('\\n')\n",
    "print('on_train的优惠券数：', on_train.Coupon_id.nunique())\n",
    "print('off_train的优惠券数：', off_train.Coupon_id.nunique())\n",
    "print('off_train领取优惠券的记录数：', off_train[off_train.Coupon_id != -1].shape[0])\n",
    "print('off_test的优惠券数：', off_test.Coupon_id.nunique())\n",
    "print('off_test领取优惠券的记录数：', off_test[off_test.Coupon_id != -1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     13,
     15,
     23,
     25,
     32,
     34,
     42
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test.shape: (113640, 6)\n",
      "df_train1.shape: (258446, 7)\n",
      "df_train2.shape: (137167, 7)\n",
      "0    235152\n",
      "1     23294\n",
      "Name: label, dtype: int64\n",
      "0    128094\n",
      "1      9073\n",
      "Name: label, dtype: int64\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "###原始数据加载###################################################\n",
    "on_train = pd.read_csv(input_path + 'ccf_online_stage1_train.csv', na_values='null' , keep_default_na=False)\n",
    "off_train = pd.read_csv(input_path + 'ccf_offline_stage1_train.csv', na_values='null' , keep_default_na=False)\n",
    "off_test = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv', na_values='null' , keep_default_na=False)\n",
    "\n",
    "#空值填-1\n",
    "on_train = on_train.fillna(-1)\n",
    "off_train = off_train.fillna(-1)\n",
    "off_test = off_test.fillna(-1)\n",
    "\n",
    "###数据集划分#####################################################\n",
    "###测试集数据\n",
    "df_test = off_test\n",
    "df_test_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160315) & (off_train.Date_received <= 20160630)) | \n",
    "                                 ((off_train.Date != -1) & (off_train.Date >= 20160315) & (off_train.Date <= 20160630))]\n",
    "df_test_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160315) & (on_train.Date_received <= 20160630)) | \n",
    "                               ((on_train.Date != -1) & (on_train.Date >= 20160315) & (on_train.Date <= 20160630))]\n",
    "\n",
    "print('df_test.shape:', df_test.shape)\n",
    "\n",
    "\n",
    "###训练集_1数据\n",
    "df_train1 = off_train[(off_train.Date_received != -1) & (off_train.Date_received >= 20160515) & (off_train.Date_received <= 20160615)]\n",
    "df_train1_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160201) & (off_train.Date_received <= 20160514)) | \n",
    "                                  ((off_train.Date != -1) & (off_train.Date >= 20160201) & (off_train.Date <= 20160514))]\n",
    "df_train1_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160201) & (on_train.Date_received <= 20160514)) | \n",
    "                                ((on_train.Date != -1) & (on_train.Date >= 20160201) & (on_train.Date <= 20160514))]\n",
    "\n",
    "print('df_train1.shape:', df_train1.shape)\n",
    "\n",
    "###训练集_2数据\n",
    "df_train2 = off_train[(off_train.Date_received != -1) & (off_train.Date_received >= 20160414) & (off_train.Date_received <= 20160514)]\n",
    "df_train2_feat_offline = off_train[((off_train.Date_received != -1) & (off_train.Date_received >= 20160101) & (off_train.Date_received <= 20160413)) | \n",
    "                                  ((off_train.Date != -1) & (off_train.Date >= 20160101) & (off_train.Date <= 20160413))]\n",
    "df_train2_feat_online = on_train[((on_train.Date_received != -1) & (on_train.Date_received >= 20160101) & (on_train.Date_received <= 20160413)) | \n",
    "                                ((on_train.Date != -1) & (on_train.Date >= 20160101) & (on_train.Date <= 20160413))]                                          \n",
    "\n",
    "print('df_train2.shape:', df_train2.shape)\n",
    "\n",
    "\n",
    "###时间格式转化、训练集打标签#####################################################\n",
    "###train1时间格式转化，打标签\n",
    "def time_convert(int_time):\n",
    "    if int_time != -1:\n",
    "        str_time = str(int(int_time))\n",
    "        year = int(str_time[0: 4])\n",
    "        month = int(str_time[4: 6])\n",
    "        day = int(str_time[6: 8])\n",
    "        datatime_time = datetime(year, month, day)\n",
    "    else:\n",
    "        datatime_time = -1\n",
    "    \n",
    "    return datatime_time\n",
    "\n",
    "df_train1['Date_received'] = df_train1.Date_received.apply(time_convert)  \n",
    "df_train1['Date'] = df_train1.Date.apply(time_convert)  \n",
    "\n",
    "df_train1['diff'] = df_train1.apply(lambda x: (x.Date - x.Date_received).days if x.Date != -1 else -1, axis=1)\n",
    "df_train1['label'] = df_train1['diff'].apply(lambda x: 0 if(x > 15 or x == -1) else 1)\n",
    "\n",
    "print(df_train1['label'].value_counts())\n",
    "\n",
    "###train2时间格式转化，打标签\n",
    "df_train2['Date_received'] = df_train2.Date_received.apply(time_convert)  \n",
    "df_train2['Date'] = df_train2.Date.apply(time_convert)  \n",
    "\n",
    "df_train2['diff'] = df_train2.apply(lambda x: (x.Date - x.Date_received).days if x.Date != -1 else -1, axis=1)\n",
    "df_train2['label'] = df_train2['diff'].apply(lambda x: 0 if(x > 15 or x == -1) else 1)\n",
    "\n",
    "print(df_train2['label'].value_counts())\n",
    "\n",
    "###test时间格式转化\n",
    "df_test['Date_received'] = df_test.Date_received.apply(time_convert)\n",
    "\n",
    "\n",
    "\n",
    "###预处理完的数据保存#######################################################\n",
    "pickle.dump(df_test, open(input_path + 'df_test.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_offline, open(input_path + 'df_test_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_online, open(input_path + 'df_test_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train1, open(input_path + 'df_train1.pkl', 'wb'))\n",
    "pickle.dump(df_train1_feat_offline, open(input_path + 'df_train1_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train1_feat_online, open(input_path + 'df_train1_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train2, open(input_path + 'df_train2.pkl', 'wb'))\n",
    "pickle.dump(df_train2_feat_offline, open(input_path + 'df_train2_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train2_feat_online, open(input_path + 'df_train2_feat_online.pkl', 'wb'))\n",
    "\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     12,
     26,
     35,
     46,
     90,
     144,
     206,
     235,
     268
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载\n",
      "用户线下特征群\n",
      "用户线上特征群\n",
      "商店特征群\n",
      "用户商家交互特征群\n",
      "优惠券特征群\n",
      "leakage特征群\n",
      "提取特征的时间为: 282\n",
      "df_train1.shape: (258446, 98)\n",
      "df_train2.shape: (137167, 98)\n",
      "df_train3.shape: (113640, 95)\n",
      "特征工程结束\n"
     ]
    }
   ],
   "source": [
    "###基础函数\n",
    "def time_convert(int_time):\n",
    "    if int_time != -1:\n",
    "        str_time = str(int(int_time))\n",
    "        year = int(str_time[0: 4])\n",
    "        month = int(str_time[4: 6])\n",
    "        day = int(str_time[6: 8])\n",
    "        datatime_time = datetime(year, month, day)\n",
    "    else:\n",
    "        datatime_time = -1\n",
    "\n",
    "    return datatime_time\n",
    "def discount_rate_trans(str_rate):\n",
    "    if str_rate == 'fixed':\n",
    "        float_rate = 0.9\n",
    "    else:\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "\n",
    "        if a != 0:\n",
    "            float_rate = (a - b) / a\n",
    "        else:\n",
    "            float_rate = float(str_rate)\n",
    "\n",
    "    return float_rate\n",
    "def discount_rate_man(str_rate):\n",
    "    if re.search(':', str_rate):\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "\n",
    "        return a\n",
    "    else:\n",
    "        return 0\n",
    "def discount_rate_jian(str_rate):\n",
    "    if re.search(':', str_rate):\n",
    "        list_ = re.findall('\\d*', str_rate)\n",
    "        a = int(list_[0])\n",
    "        b = int(list_[2])\n",
    "\n",
    "        return b\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "###六大特征群\n",
    "def user_off_feat(df_train1, df_train1_feat_offline):\n",
    "    #用户领取优惠券的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Date_received != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_count'])\n",
    "    \n",
    "    #用户领取优惠券，但没有消费的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date == -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_butNotConsume_count'])\n",
    "    \n",
    "    #用户领取优惠券，而且消费了的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_received_coupon_andConsume_count'])\n",
    "\n",
    "    #用户领取优惠券后的核销率：\n",
    "    df_train1['user_received_coupon_ConsumeRate'] = df_train1.user_received_coupon_andConsume_count / df_train1.user_received_coupon_count\n",
    "\n",
    "    #用户核销优惠券的平均折扣率，最大折扣率，最小折扣率 ：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat['Discount_rate'] = df_tem_feat.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_aveDiscountRate'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_maxDiscountRate'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['User_id'], ['Discount_rate'], ['user_consume_coupon_minDiscountRate'], na=-1)\n",
    "\n",
    "    #用户核销过优惠券的不同商家数量；以及占所有商家的比重：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['User_id'], ['Merchant_id'], ['user_consume_coupon_MerchantNunique'])\n",
    "    df_train1['user_consume_coupon_MerchantRate'] = df_train1['user_consume_coupon_MerchantNunique'] / df_tem_feat.Merchant_id.nunique()\n",
    "\n",
    "    #用户核销过的不同优惠券数量；以及占所有核销优惠券的比重：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['user_consume_coupon_Nunique'])\n",
    "    df_train1['user_consume_coupon_Rate'] = df_train1['user_consume_coupon_Nunique'] / df_train1['user_received_coupon_andConsume_count']\n",
    "\n",
    "    #用户平均核销每个商家多少张优惠券：\n",
    "    df_train1['user_consume_coupon_AveCount'] = df_train1['user_received_coupon_andConsume_count'] / df_train1['user_consume_coupon_MerchantNunique']\n",
    "\n",
    "    #用户核销优惠券中，离商家的平均距离，最远距离，最近距离\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)& \n",
    "                                         (df_train1_feat_offline.Distance != -1)].copy()\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_meanDistance'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_maxDistance'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['User_id'], ['Distance'], ['user_consume_coupon_minDistance'], na=-1)\n",
    "\n",
    "    return df_train1\n",
    "def user_on_feat(df_train1, df_train1_feat_online):\n",
    "    #用户线上消费次数：\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_Consume_count'])\n",
    "    \n",
    "    #用户线上不消费次数：\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action != 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_notConsume_count'])\n",
    "    \n",
    "    #用户线上点击次数，购买次数，领取次数；点击率，购买率，领取率\n",
    "    df_tem_feat = df_train1_feat_online.copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_all_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 0].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_0_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_1_count'])\n",
    "    \n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 2].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_action_2_count'])\n",
    "    \n",
    "    df_train1['on_user_action_0_rate'] = df_train1['on_user_action_0_count'] / df_train1['on_user_action_all_count']\n",
    "    df_train1['on_user_action_1_rate'] = df_train1['on_user_action_1_count'] / df_train1['on_user_action_all_count']\n",
    "    df_train1['on_user_action_2_rate'] = df_train1['on_user_action_2_count'] / df_train1['on_user_action_all_count']\n",
    "    \n",
    "    #用户线上优惠券的（领取+核销）次数：\n",
    "    df_tem_feat = df_train1_feat_online[(df_train1_feat_online.Coupon_id != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['on_user_Coupon_receive_count'])\n",
    "    \n",
    "    #用户线上优惠券核销的次数：\n",
    "    df_tem_feat = df_train1_feat_online[(df_train1_feat_online.Coupon_id != -1) & (df_train1_feat_online.Action == 1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Action'], ['on_user_Coupon_andConsume_count'])\n",
    "    \n",
    "    #用户线上优惠券核销率：\n",
    "    df_train1['on_user_received_Consume_rate'] = df_train1['on_user_action_Consume_count'] / (df_train1['on_user_Coupon_receive_count'] + 0.1)\n",
    "    \n",
    "    #用户线下不消费的次数，占线上线下总的不消费次数比重\n",
    "    df_train1['on_notConsume_rate'] = df_train1['user_received_coupon_butNotConsume_count'] / \\\n",
    "                 (df_train1['user_received_coupon_butNotConsume_count'] + df_train1['on_user_action_notConsume_count'] + 0.1)\n",
    "\n",
    "    #用户线下优惠券核销次数，占线上线下总的优惠券核销次数比重\n",
    "    df_train1['on_coupon_Consume_rate'] = df_train1['user_received_coupon_andConsume_count'] / \\\n",
    "                 (df_train1['user_received_coupon_andConsume_count'] + df_train1['on_user_Coupon_andConsume_count'] + 0.1)\n",
    "\n",
    "    #用户线上领取优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_online[df_train1_feat_online.Action == 2].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id'], ['Coupon_id'], ['on_user_received_coupon_count'])\n",
    "    \n",
    "    #用户线下领取优惠券次数，占线上线下领取次数的比重\n",
    "    df_train1['on_received_coupon_rate'] = df_train1['user_received_coupon_count'] / \\\n",
    "                 (df_train1['user_received_coupon_count'] + df_train1['on_user_received_coupon_count'] + 0.1)\n",
    "    \n",
    "    return df_train1\n",
    "def Merchant_feat(df_train1, df_train1_feat_offline):\n",
    "    #商家优惠券发放次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_count'])\n",
    "    \n",
    "    #商家优惠券发放的种类\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_nunique'])\n",
    "    \n",
    "    #商家优惠券发放后，不被核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != 1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_butNotConsume_count'])\n",
    "    \n",
    "    #商家优惠券发放后，被核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_andConsume_count'])\n",
    "\n",
    "    #商家优惠券发放后，被核销的比率：\n",
    "    df_train1['Merchant_send_coupon_andConsume_rate'] = df_train1['Merchant_send_coupon_andConsume_count'] / \\\n",
    "                                                        df_train1['Merchant_send_coupon_count']\n",
    "    \n",
    "    #商家优惠券核销的平均折率，最大折率，最小折率\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat['Discount_rate'] = df_tem_feat.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_aveDiscountRate'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_maxDiscountRate'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['Merchant_id'], ['Discount_rate'], ['Merchant_coupon_Consume_minDiscountRate'], na=-1)\n",
    "    \n",
    "    #核销商家优惠券的，不同用户数量；以及占所有领取次数的比重\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['User_id'], ['Merchant_send_coupon_userNunique'])\n",
    "    df_train1['Merchant_send_coupon_userRate'] = df_train1['Merchant_send_coupon_userNunique'] / df_train1['Merchant_send_coupon_count']\n",
    "    \n",
    "    #商家平均每个用户核销优惠券多少张\n",
    "    df_train1['Merchant_aveUser_CouponCount'] = df_train1['Merchant_send_coupon_andConsume_count'] / df_train1['Merchant_send_coupon_userNunique']\n",
    "    \n",
    "    #商家被核销过的不同优惠券数量；\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_nunique(df_train1, df_tem_feat, ['Merchant_id'], ['Coupon_id'], ['Merchant_send_coupon_andConsume_nunique'])\n",
    "    \n",
    "    \n",
    "    #商家被核销过的不同优惠券数量，占所有领取过的不同优惠券比重\n",
    "    df_train1['Merchant_send_coupon_andConsume_nunique'] = df_train1['Merchant_send_coupon_andConsume_nunique'] / \\\n",
    "                                                               df_train1['Merchant_send_coupon_nunique']\n",
    "    \n",
    "    #商家平均每种优惠券核销多少张：\n",
    "    df_train1['Merchant_aveCoupon_count'] = df_train1['Merchant_send_coupon_andConsume_count'] / df_train1['Merchant_send_coupon_nunique']\n",
    "    \n",
    "    #商家被核销的优惠券中，平均，最大，最小距离。\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_meanDistance'], na=-1)\n",
    "    df_train1 = feat_max(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_maxDistance'], na=-1)\n",
    "    df_train1 = feat_min(df_train1, df_tem_feat, ['Merchant_id'], ['Distance'], ['Merchant_send_coupon_minDistance'], na=-1)\n",
    "    \n",
    "    #商家被核销的优惠券中，核销的平均时间\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_tem_feat.Date = df_tem_feat.Date.apply(time_convert)\n",
    "    df_tem_feat.Date_received = df_tem_feat.Date_received.apply(time_convert)\n",
    "    df_tem_feat['diff'] = (df_tem_feat.Date - df_tem_feat.Date_received).dt.days\n",
    "    df_train1 = feat_mean(df_train1, df_tem_feat, ['Merchant_id'], ['diff'], ['Merchant_coupon_Consume_AveTime'], na=-1)\n",
    "    \n",
    "    return df_train1\n",
    "def user_Merchant_feat(df_train1, df_train1_feat_offline):\n",
    "    #用户领取商家优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Date_received != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，但不核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date == -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_notConsume_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，核销的次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Date_received != -1) & (df_train1_feat_offline.Date != -1)].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['User_id', 'Merchant_id'], ['Coupon_id'], ['user_get_Merchant_coupon_Consume_count'])\n",
    "    \n",
    "    #用户领取商家优惠券后，核销率\n",
    "    df_train1['user_get_Merchant_coupon_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['user_get_Merchant_coupon_count']\n",
    "    \n",
    "    #用户对每个商家的不核销次数，占用户总的不核销次数的比重：\n",
    "    df_train1['userMerchant_notConsume_to_user_notConsume_rate'] = df_train1['user_get_Merchant_coupon_notConsume_count'] / df_train1['user_received_coupon_butNotConsume_count']\n",
    "    \n",
    "    #用户对每个商家的核销次数，占用户总的核销次数的比重：\n",
    "    df_train1['userMerchant_Consume_to_user_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['user_received_coupon_andConsume_count']\n",
    "    \n",
    "    #用户对每个商家的不核销次数，占商家总的不核销次数的比重：\n",
    "    df_train1['userMerchant_notConsume_to_Merchant_notConsume_rate'] = df_train1['user_get_Merchant_coupon_notConsume_count'] / df_train1['Merchant_send_coupon_butNotConsume_count']\n",
    "    \n",
    "    #用户对每个商家的核销次数，占商家总的核销次数的比重：\n",
    "    df_train1['userMerchant_Consume_to_Merchant_Consume_rate'] = df_train1['user_get_Merchant_coupon_Consume_count'] / df_train1['Merchant_send_coupon_andConsume_count']\n",
    "    \n",
    "    return df_train1\n",
    "def Coupon_feat(df_train1, df_train1_feat_offline):\n",
    "    df_train1['discount_rate_type'] = df_train1.Discount_rate.apply(lambda x: 0 if re.search(':', x) else 1)\n",
    "    df_train1['discount_rate_man'] = df_train1.Discount_rate.apply(discount_rate_man)\n",
    "    df_train1['discount_rate_jian'] = df_train1.Discount_rate.apply(discount_rate_jian)\n",
    "    df_train1['Discount_rate'] = df_train1.Discount_rate.apply(discount_rate_trans)\n",
    "    df_train1['day'] = df_train1.Date_received.dt.day\n",
    "    df_train1['weekday'] = df_train1.Date_received.dt.weekday\n",
    "    df_train1['is_weekend'] = df_train1.weekday.apply(lambda x: 1 if x<=4 else 0)\n",
    "    \n",
    "    #该优惠券在，历史上出现的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id'], ['Merchant_id'], ['Coupon_appear_count'])\n",
    "    \n",
    "    #该优惠券在，历史上核销的次数：\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & df_train1_feat_offline.Date != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id'], ['Merchant_id'], ['Coupon_Consume_count'])\n",
    "    \n",
    "    #该优惠券在，历史上的核销率：\n",
    "    df_train1['Coupon_Consume_rate'] = df_train1['Coupon_Consume_count'] / (df_train1['Coupon_appear_count'] + 0.1)\n",
    "\n",
    "    #历史上，该用户领取该优惠券的次数\n",
    "    df_tem_feat = df_train1_feat_offline[df_train1_feat_offline.Coupon_id != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id', 'User_id'], ['Merchant_id'], ['Coupon_User_appear_count'])\n",
    "    \n",
    "    #历史上，该用户领取该优惠券后的核销次数\n",
    "    df_tem_feat = df_train1_feat_offline[(df_train1_feat_offline.Coupon_id != -1) & df_train1_feat_offline.Date != -1].copy()\n",
    "    df_train1 = feat_count(df_train1, df_tem_feat, ['Coupon_id', 'User_id'], ['Merchant_id'], ['Coupon_User_Consume_count'])\n",
    "    \n",
    "    #历史上，该用户领取该优惠券后的核销率\n",
    "    df_train1['Coupon_User_Consume_rate'] = df_train1['Coupon_User_Consume_count'] / (df_train1['Coupon_User_appear_count'] + 0.1)\n",
    "    \n",
    "    \n",
    "    return df_train1\n",
    "def leakage_feat(df_train1):\n",
    "    #用户领取的所有优惠券数目\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id'], ['Coupon_id'], ['leak_User_receive_all_Coupon_count'])\n",
    "    \n",
    "    #用户领取的相同优惠券数目\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Coupon_id'], ['Merchant_id'], ['leak_User_receive_same_Coupon_count'])\n",
    "    \n",
    "    #用户领取同一优惠券的最大/最小时间： \n",
    "    df_train1_tem = df_train1.groupby(['User_id', 'Coupon_id'])['Merchant_id'].count().reset_index().rename(columns={'Merchant_id': 'count'})\n",
    "    df_train1_tem = df_train1_tem[df_train1_tem['count'] >= 2]\n",
    "    df_train1_tem = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='inner')\n",
    "    df_train1_tem['time'] = df_train1_tem['Date_received'].dt.day\n",
    "    \n",
    "    df_train1 = feat_max(df_train1, df_train1_tem, ['User_id', 'Coupon_id'], ['time'], ['leak_User_receive_same_Coupon_maxTime'])\n",
    "    df_train1 = feat_min(df_train1, df_train1_tem, ['User_id', 'Coupon_id'], ['time'], ['leak_User_receive_same_Coupon_minTime'])\n",
    "    \n",
    "    #是否是最后一次领取，是否是第一次领取：\n",
    "    df_train1['is_last_receive'] = df_train1['leak_User_receive_same_Coupon_maxTime'] - (df_train1['Date_received']).dt.day\n",
    "    df_train1['is_first_receive'] = (df_train1['Date_received']).dt.day - df_train1['leak_User_receive_same_Coupon_minTime']\n",
    "    \n",
    "    def is_firstOrLast_day(diff_day):\n",
    "        if diff_day == 0:\n",
    "            return 1\n",
    "        elif diff_day > 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    df_train1['is_last_receive'] = df_train1['is_last_receive'].apply(is_firstOrLast_day)\n",
    "    df_train1['is_first_receive'] = df_train1['is_first_receive'].apply(is_firstOrLast_day)\n",
    "    \n",
    "    #用户当天领取的优惠券总数：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Date_received'], ['Coupon_id'], ['leak_User_theDate_received_Coupon_count'])\n",
    "    \n",
    "    #用户当天领取相同优惠券总数：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['User_id', 'Date_received', 'Coupon_id'], ['Merchant_id'], ['leak_User_theDate_received_Coupon_count'])\n",
    "    \n",
    "    #用户领取不同商家数目：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['User_id'], ['Merchant_id'], ['leak_User_receive_Merchant_nunique'])\n",
    "    \n",
    "    #用户领取的所有优惠券种类\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['User_id'], ['Coupon_id'], ['leak_User_receive_Coupon_nunique'])\n",
    "\n",
    "    #商家被领取的优惠券数目：\n",
    "    df_train1 = feat_count(df_train1, df_train1, ['Merchant_id'], ['Coupon_id'], ['leak_Merchant_send_Coupon_count'])\n",
    "\n",
    "    #商家被多少不用用户领取：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['Merchant_id'], ['User_id'], ['leak_Merchant_get_User_nunique'])\n",
    "    \n",
    "    #商家发行的所有优惠券种类：\n",
    "    df_train1 = feat_nunique(df_train1, df_train1, ['Merchant_id'], ['Coupon_id'], ['leak_Merchant_send_Coupon_nunique'])\n",
    "    \n",
    "    #同一张优惠券，用户这次领取与上一次/下一次领取的时间间隔：（超级强特）\n",
    "    def get_day_gap_before(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8])) - \n",
    "                       datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    def get_day_gap_after(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8])) - \n",
    "                       datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id', 'Coupon_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "\n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_same_Coupon_timeGap_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_before)\n",
    "    df_train1_tem_2['receive_same_Coupon_timeGap_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_same_Coupon_timeGap_before', 'receive_same_Coupon_timeGap_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #用户这次领取与上一次/下一次领取的时间间隔：\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "    \n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_Coupon_timeGap_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_before)\n",
    "    df_train1_tem_2['receive_Coupon_timeGap_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_day_gap_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_Coupon_timeGap_before', 'receive_Coupon_timeGap_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    \n",
    "    #同一张优惠券，用户此次之前/之后领取的所有优惠券数目：\n",
    "    def get_Coupon_count_before(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8])) - \n",
    "                       datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return len(gaps)\n",
    "    def get_Coupon_count_after(the_DateReceived_all_DateReceived):\n",
    "        the_DateReceived, all_DateReceived = the_DateReceived_all_DateReceived.split('-')\n",
    "        all_DateReceived = all_DateReceived.split(':')\n",
    "\n",
    "        gaps = []\n",
    "        for day in all_DateReceived:\n",
    "            the_gap = (datetime(int(day[0: 4]), int(day[4: 6]), int(day[6: 8])) - \n",
    "                       datetime(int(the_DateReceived[0: 4]), int(the_DateReceived[4: 6]), int(the_DateReceived[6: 8]))).days\n",
    "            if the_gap > 0:\n",
    "                gaps.append(the_gap)\n",
    "        if len(gaps) == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return len(gaps)\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id', 'Coupon_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "\n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id', 'Coupon_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_sameCoupon_count_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_before)\n",
    "    df_train1_tem_2['receive_sameCoupon_count_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_sameCoupon_count_before', 'receive_sameCoupon_count_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #用户此次之前/之后领取的所有优惠券数目：\n",
    "    df_train1_tem = df_train1.copy()\n",
    "    df_train1_tem['Date_received'] = df_train1_tem['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem = df_train1_tem.groupby(['User_id'])['Date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    df_train1_tem = df_train1_tem.rename(columns={'Date_received': 'all_DateReceived'})\n",
    "    \n",
    "    df_train1_tem_2 = pd.merge(df_train1, df_train1_tem, on=['User_id'], how='left')\n",
    "    df_train1_tem_2['Date_received'] = df_train1_tem_2['Date_received'].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    df_train1_tem_2['the_DateReceived_all_DateReceived'] = df_train1_tem_2.Date_received + '-' + df_train1_tem_2.all_DateReceived\n",
    "    df_train1_tem_2['receive_Coupon_count_before'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_before)\n",
    "    df_train1_tem_2['receive_Coupon_count_after'] = df_train1_tem_2.the_DateReceived_all_DateReceived.apply(get_Coupon_count_after)\n",
    "    df_train1_tem_2 = df_train1_tem_2[['receive_Coupon_count_before', 'receive_Coupon_count_after']]\n",
    "    \n",
    "    df_train1 = pd.concat([df_train1.reset_index(drop=True), df_train1_tem_2.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    \n",
    "    return df_train1\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "print('数据加载')\n",
    "df_test = pickle.load(open(input_path + 'df_test.pkl', 'rb'))\n",
    "df_test_feat_offline = pickle.load(open(input_path + 'df_test_feat_offline.pkl', 'rb'))\n",
    "df_test_feat_online = pickle.load(open(input_path + 'df_test_feat_online.pkl', 'rb'))\n",
    "\n",
    "df_train1 = pickle.load(open(input_path + 'df_train1.pkl', 'rb'))\n",
    "df_train1_feat_offline = pickle.load(open(input_path + 'df_train1_feat_offline.pkl', 'rb'))\n",
    "df_train1_feat_online = pickle.load(open(input_path + 'df_train1_feat_online.pkl', 'rb'))\n",
    "\n",
    "df_train2 = pickle.load(open(input_path + 'df_train2.pkl', 'rb'))\n",
    "df_train2_feat_offline = pickle.load(open(input_path + 'df_train2_feat_offline.pkl', 'rb'))\n",
    "df_train2_feat_online = pickle.load(open(input_path + 'df_train2_feat_online.pkl', 'rb'))\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "print('用户线下特征群')\n",
    "df_train1 = user_off_feat(df_train1, df_train1_feat_offline)\n",
    "df_train2 = user_off_feat(df_train2, df_train2_feat_offline)\n",
    "df_test = user_off_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "print('用户线上特征群')\n",
    "df_train1 = user_on_feat(df_train1, df_train1_feat_online)\n",
    "df_train2 = user_on_feat(df_train2, df_train2_feat_online)\n",
    "df_test = user_on_feat(df_test, df_test_feat_online)\n",
    "\n",
    "print('商店特征群')\n",
    "df_train1 = Merchant_feat(df_train1, df_train1_feat_offline)\n",
    "df_train2 = Merchant_feat(df_train2, df_train2_feat_offline)\n",
    "df_test = Merchant_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "print('用户商家交互特征群')\n",
    "df_train1 = user_Merchant_feat(df_train1, df_train1_feat_offline)\n",
    "df_train2 = user_Merchant_feat(df_train2, df_train2_feat_offline)\n",
    "df_test = user_Merchant_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "print('优惠券特征群')\n",
    "df_train1 = Coupon_feat(df_train1, df_train1_feat_offline)\n",
    "df_train2 = Coupon_feat(df_train2, df_train2_feat_offline)\n",
    "df_test = Coupon_feat(df_test, df_test_feat_offline)\n",
    "\n",
    "print('leakage特征群')\n",
    "df_train1 = leakage_feat(df_train1)\n",
    "df_train2 = leakage_feat(df_train2)\n",
    "df_test = leakage_feat(df_test)\n",
    "\n",
    "\n",
    "pickle.dump(df_train1, open(input_path + 'df_train1_feat.pkl', 'wb'))\n",
    "pickle.dump(df_train2, open(input_path + 'df_train2_feat.pkl', 'wb'))\n",
    "pickle.dump(df_test, open(input_path + 'df_test_feat.pkl', 'wb'))\n",
    "\n",
    "print('提取特征的时间为:', int(time() - start_time))\n",
    "print(\"df_train1.shape:\", df_train1.shape)\n",
    "print(\"df_train2.shape:\", df_train2.shape)\n",
    "print(\"df_train3.shape:\", df_test.shape)\n",
    "print('特征工程结束')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train1 = pickle.load(open(input_path + 'df_train1_feat.pkl', 'rb'))\n",
    "df_train2 = pickle.load(open(input_path + 'df_train2_feat.pkl', 'rb'))\n",
    "df_test = pickle.load(open(input_path + 'df_test_feat.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 20%随机验证集（不准确，不用！！）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     40,
     47
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[500]\tvalid_0's binary_logloss: 0.185174\n",
      "[1000]\tvalid_0's binary_logloss: 0.183769\n",
      "Early stopping, best iteration is:\n",
      "[904]\tvalid_0's binary_logloss: 0.183722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.06,\n",
       "        max_bin=255, max_depth=5, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=10000, nthread=-1, num_leaves=30,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=0, silent=True,\n",
       "        sub_feature=0.8, subsample=0.8, subsample_for_bin=50000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均auc为： 0.8017468961530861\n",
      "训练预测的时间为: 63\n"
     ]
    }
   ],
   "source": [
    "###训练集、验证集############\n",
    "def clf_evaluate(df_Coupon_y, y_pred):\n",
    "    y_pred = y_pred[:, 1]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    \n",
    "    df_val_auc = df_Coupon_y[['Coupon_id', 'label']]\n",
    "    df_val_auc['pred_prob'] = y_pred\n",
    "\n",
    "    # 计算平均AUC\n",
    "    aucs = []\n",
    "    for name, group in df_val_auc.groupby(['Coupon_id']):   \n",
    "        if len(group['label'].unique()) != 2:\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(group['label'], group['pred_prob'], pos_label=1)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    print('平均auc为：', np.average(aucs))\n",
    "\n",
    "    \n",
    "\n",
    "X_train1 = df_train1.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Merchant_id'], axis=1)\n",
    "y_train1 = df_train1['label']\n",
    "\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train1, y_train1, test_size=0.2, random_state=1254)\n",
    "df_Coupon_y = pd.concat([X_val_.Coupon_id, y_val_], axis=1)\n",
    "\n",
    "# 奇怪，为什么id特征加进去分数提高那么多，是leak吗？？\n",
    "X_train = X_train1.drop(['Coupon_id'], axis=1)\n",
    "X_train_ = X_train_.drop(['Coupon_id'], axis=1)\n",
    "X_val_ = X_val_.drop(['Coupon_id'], axis=1)\n",
    "\n",
    "\n",
    "###测试集###################\n",
    "X_test = df_test.drop(['User_id', 'Merchant_id', 'Coupon_id',  'Date_received',], axis=1)\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "clf = lgb.LGBMClassifier(n_estimators=10000,\n",
    "                         learning_rate=0.06,\n",
    "                         max_depth=5,\n",
    "                         num_leaves=30,\n",
    "                         objective='binary',\n",
    "                         subsample=0.8,\n",
    "                         sub_feature=0.8,)\n",
    "clf.fit(X_train_, y_train_, eval_set=[(X_val_, y_val_)], \n",
    "        eval_metric='binary_logloss',early_stopping_rounds=100, verbose = 500,)\n",
    "y_pred = clf.predict_proba(X_val_, num_iteration=clf.best_iteration)\n",
    "feat_impo = sorted(zip(X_train_.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "clf_evaluate(df_Coupon_y, y_pred)\n",
    "\n",
    "print('训练预测的时间为:', int(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 划分数据集做验证集（训练集：train2；验证集train1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape: (137167, 91)\n",
      "X_train1.shape: (258446, 91)\n",
      "X_test.shape: (113640, 91)\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.231941\n",
      "[200]\tvalid_0's binary_logloss: 0.233949\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.231472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.06,\n",
       "        max_bin=255, max_depth=5, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=10000, nthread=-1, num_leaves=30,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=0, silent=True,\n",
       "        sub_feature=0.9, subsample=0.9, subsample_for_bin=50000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均auc为： 0.7504008583682287\n",
      "训练预测的时间为: 22\n"
     ]
    }
   ],
   "source": [
    "def clf_evaluate(df_Coupon_y, y_pred):\n",
    "    y_pred = y_pred[:, 1]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    \n",
    "    df_val_auc = df_Coupon_y[['Coupon_id', 'label']]\n",
    "    df_val_auc['pred_prob'] = y_pred\n",
    "\n",
    "    # 计算平均AUC\n",
    "    aucs = []\n",
    "    for name, group in df_val_auc.groupby(['Coupon_id']):   \n",
    "        if len(group['label'].unique()) != 2:\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(group['label'], group['pred_prob'], pos_label=1)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    print('平均auc为：', np.average(aucs))\n",
    "\n",
    "X_train1 = df_train1.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "y_train1 = df_train1['label']\n",
    "\n",
    "X_train2 = df_train2.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "y_train2 = df_train2['label']\n",
    "\n",
    "X_test = df_test.drop(['Date_received', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "\n",
    "# print('特征选择')\n",
    "# seltor, X_train2, X_train1, X_test = RFECV_feature_sel(X_train2, y_train2, X_train1, X_test)\n",
    "# feat_import, X_train2, X_train1, X_test = Tree_feature_sel(X_train2, y_train2, X_train1, y_train1, X_test, 80)\n",
    "\n",
    "print(\"X_train2.shape:\", X_train2.shape)\n",
    "print(\"X_train1.shape:\", X_train1.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "clf = lgb.LGBMClassifier(n_estimators=10000,\n",
    "                         learning_rate=0.06,\n",
    "                         max_depth=5,\n",
    "                         num_leaves=30,\n",
    "                         objective='binary',\n",
    "                         subsample=0.9,\n",
    "                         sub_feature=0.9,)\n",
    "clf.fit(X_train2, y_train2, eval_set=[(X_train1, y_train1)], \n",
    "        eval_metric='binary_logloss',early_stopping_rounds=100, verbose = 100,)\n",
    "y_pred = clf.predict_proba(X_train1, num_iteration=clf.best_iteration)\n",
    "feat_impo = sorted(zip(X_train2.columns, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "clf_evaluate(df_train1, y_pred)\n",
    "\n",
    "print('训练预测的时间为:', int(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线上提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.06,\n",
       "        max_bin=255, max_depth=5, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=180, nthread=-1, num_leaves=30,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=0, silent=True,\n",
       "        sub_feature=0.9, subsample=0.9, subsample_for_bin=50000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game over\n"
     ]
    }
   ],
   "source": [
    "###数据集合并\n",
    "X_train1 = pd.DataFrame(X_train1)\n",
    "X_train2 = pd.DataFrame(X_train2)\n",
    "X_train_all = pd.concat([X_train1, X_train2]).reset_index(drop=True)\n",
    "y_train_all = pd.concat([y_train1, y_train2]).reset_index(drop=True)\n",
    "\n",
    "###合并的数据集上训练和预测\n",
    "clf = lgb.LGBMClassifier(n_estimators=180,\n",
    "                         learning_rate=0.06,\n",
    "                         max_depth=5,\n",
    "                         num_leaves=30,\n",
    "                         objective='binary',\n",
    "                         subsample=0.9,\n",
    "                         sub_feature=0.9,)\n",
    "clf.fit(X_train_all, y_train_all)\n",
    "y_pred = clf.predict_proba(X_test, num_iteration=180)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "###生成提交\n",
    "submission = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')[['User_id', 'Coupon_id', 'Date_received']]\n",
    "df_prob = pd.DataFrame(y_pred, columns=['Probability'])\n",
    "submission = pd.concat([submission, df_prob], axis=1)\n",
    "submission.to_csv(submi_path + '8_12_all_数据集合并！！！.csv', index=False, header=None)\n",
    "\n",
    "print('game over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 换一下冠军的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape: (137167, 91)\n",
      "X_train1.shape: (258446, 91)\n",
      "X_test.shape: (113640, 91)\n"
     ]
    }
   ],
   "source": [
    "df_train1 = pickle.load(open(input_path + 'df_train1.pkl', 'rb'))\n",
    "df_train2 = pickle.load(open(input_path + 'df_train2.pkl', 'rb'))\n",
    "df_test = pickle.load(open(input_path + 'df_test.pkl', 'rb'))\n",
    "\n",
    "X_train1 = df_train1.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "y_train1 = df_train1['label']\n",
    "\n",
    "X_train2 = df_train2.drop(['label', 'Date_received', 'Date', 'diff', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "y_train2 = df_train2['label']\n",
    "\n",
    "X_test = df_test.drop(['Date_received', 'User_id', 'Coupon_id', 'Merchant_id'], axis=1)\n",
    "\n",
    "print(\"X_train2.shape:\", X_train2.shape)\n",
    "print(\"X_train1.shape:\", X_train1.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "\n",
    "X_train1 = pd.DataFrame(X_train1)\n",
    "X_train2 = pd.DataFrame(X_train2)\n",
    "X_train_all = pd.concat([X_train1, X_train2]).reset_index(drop=True)\n",
    "y_train_all = pd.concat([y_train1, y_train2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.840919\tval-auc:0.773653\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 300 rounds.\n",
      "[2]\ttrain-auc:0.854267\tval-auc:0.794892\n",
      "平均auc为： 0.6911034584604858\n"
     ]
    }
   ],
   "source": [
    "def clf_evaluate(df_Coupon_y, y_pred):\n",
    "     #y_pred = y_pred[:, 1]  #因为sklearn输出每个类别的概率，手动选择1类\n",
    "    \n",
    "    df_val_auc = df_Coupon_y[['Coupon_id', 'label']]\n",
    "    df_val_auc['pred_prob'] = y_pred\n",
    "\n",
    "    # 计算平均AUC\n",
    "    aucs = []\n",
    "    for name, group in df_val_auc.groupby(['Coupon_id']):   \n",
    "        if len(group['label'].unique()) != 2:\n",
    "            continue\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(group['label'], group['pred_prob'], pos_label=1)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    print('平均auc为：', np.average(aucs))\n",
    "\n",
    "dataset1 = xgb.DMatrix(X_train2, label=y_train2)\n",
    "dataset2 = xgb.DMatrix(X_train1, label=y_train1)\n",
    "\n",
    "params={'booster':'gbtree',\n",
    "        'objective': 'rank:pairwise',\n",
    "        'eval_metric':'auc',\n",
    "        'gamma':0.1,\n",
    "        'min_child_weight':1.1,\n",
    "        'max_depth':5,\n",
    "        'lambda':10,\n",
    "        'subsample':0.7,\n",
    "        'colsample_bytree':0.7,\n",
    "        'colsample_bylevel':0.7,\n",
    "        'eta': 0.01,\n",
    "        'tree_method':'exact',\n",
    "        'seed':0,\n",
    "        'nthread':12\n",
    "        }\n",
    "\n",
    "##train on dataset1, evaluate on dataset2\n",
    "watchlist = [(dataset1,'train'),(dataset2,'val')]\n",
    "model = xgb.train(params, dataset1, num_boost_round=3, evals=watchlist, \n",
    "                  early_stopping_rounds=300, verbose_eval=300)\n",
    "y_pred = model.predict(dataset2)\n",
    "y_pred = MinMaxScaler().fit_transform(np.array(y_pred).reshape(-1, 1))\n",
    "\n",
    "clf_evaluate(df_train1, y_pred)\n",
    "\n",
    "\n",
    "# dataset3_preds.sort_values(by=['coupon_id','prob'],inplace=True)\n",
    "# dataset3_preds.to_csv(\"xgb_preds.csv\",index=None,header=None)\n",
    "# print (dataset3_preds.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset12 = xgb.DMatrix(X_train_all, label=y_train_all)\n",
    "dataset3 = xgb.DMatrix(X_test)\n",
    "dataset3_preds = pd.read_csv(input_path + 'ccf_offline_stage1_test_revised.csv')[['User_id', 'Coupon_id', 'Date_received']]\n",
    "\n",
    "params={'booster':'gbtree',\n",
    "        'objective': 'rank:pairwise',\n",
    "        'eval_metric':'auc',\n",
    "        'gamma':0.1,\n",
    "        'min_child_weight':1.1,\n",
    "        'max_depth':5,\n",
    "        'lambda':10,\n",
    "        'subsample':0.7,\n",
    "        'colsample_bytree':0.7,\n",
    "        'colsample_bylevel':0.7,\n",
    "        'eta': 0.01,\n",
    "        'tree_method':'exact',\n",
    "        'seed':0,\n",
    "        'nthread':12\n",
    "        }\n",
    "watchlist = [(dataset12, 'train')]\n",
    "model = xgb.train(params, dataset12, num_boost_round=10, evals=watchlist)\n",
    "\n",
    "#predict test set\n",
    "dataset3_preds['prob'] = model.predict(dataset3)\n",
    "dataset3_preds.prob = MinMaxScaler().fit_transform(np.array(dataset3_preds.prob).reshape(-1, 1))\n",
    "\n",
    "#提交\n",
    "submission.to_csv(submi_path + '冠军的模型！！！.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 可能用到的代码保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    #用户此次之后/之前领取的所有优惠券数目：\n",
    "    def after_Coupon_count(df_user):\n",
    "        count = df_user.shape[0]\n",
    "        df_user['leak_after_User_receive_Coupon_count'] = list(range(count-1, -1, -1))\n",
    "        df_user['leak_pre_User_receive_Coupon_count'] = list(range(0, count))\n",
    "\n",
    "        return df_user\n",
    "    df_train1 = df_train1.groupby(['User_id']).apply(after_Coupon_count).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    #用户上一次/下一次领取的时间间隔：\n",
    "    def receive_Coupon_gap(df_user):\n",
    "        df_user['shift_up'] = df_user['Date_received'].shift(-1)\n",
    "        df_user['shift_down'] = df_user['Date_received'].shift(1)\n",
    "#         df_user['receive_Coupon_gap_pre'] = (df_user['Date_received'] - df_user['shift_down']).dt.days.fillna(-1)\n",
    "#         df_user['receive_Coupon_gap_after'] = (df_user['shift_up'] - df_user['Date_received']).dt.days.fillna(-1)\n",
    "\n",
    "        return df_user\n",
    "    df_train1 = df_train1.groupby(['User_id']).apply(receive_Coupon_gap).reset_index(drop=True)\n",
    "    df_train1 = df_train1.drop(['shift_up', 'shift_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train1 = pickle.load(open(input_path + 'df_train1.pkl', 'rb'))\n",
    "df_train1_tem = df_train1.copy()[0: 50]\n",
    "\n",
    "#用户上一次/下一次领取的时间间隔：\n",
    "def receive_Coupon_gap(df_user):\n",
    "    df_user['shift_up'] = df_user['Date_received'].shift(-1)\n",
    "    df_user['shift_down'] = df_user['Date_received'].shift(1)\n",
    "    df_user['receive_Coupon_gap_pre'] = (df_user['Date_received'] - df_user['shift_down']).dt.days.fillna(-1)\n",
    "    df_user['receive_Coupon_gap_after'] = (df_user['shift_up'] - df_user['Date_received']).dt.days.fillna(-1)\n",
    "    \n",
    "    global i\n",
    "    i += 1\n",
    "    if i%10000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    return df_user\n",
    "\n",
    "i = 0\n",
    "df_train1 = df_train1.groupby(['User_id']).apply(receive_Coupon_gap).reset_index(drop=True)\n",
    "df_train1 = df_train1.drop(['shift_up', 'shift_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#用户此次“之后”/“之前”领取的所有优惠券数目\n",
    "df_all_user_tem = pd.DataFrame(columns=['User_id', 'leak_after_User_receive_Coupon_count', 'leak_pre_User_receive_Coupon_count'])\n",
    "user_set = df_train1.User_id.unique()\n",
    "i = 0\n",
    "for user in user_set:\n",
    "    df_user_tem = df_train1[df_train1.User_id == user].copy()[['User_id']]\n",
    "    count = df_user_tem.shape[0]\n",
    "    df_user_tem['leak_after_User_receive_Coupon_count'] = list(range(count-1, -1, -1))\n",
    "    df_user_tem['leak_pre_User_receive_Coupon_count'] = list(range(0, count))\n",
    "    df_all_user_tem = pd.concat([df_all_user_tem, df_user_tem]).reset_index(drop=True)\n",
    "    i += 1\n",
    "    print(i)\n",
    "df_all_user_tem = df_all_user_tem.drop('User_id', axis=1)\n",
    "df_train1 = pd.concat([df_train1, df_all_user_tem], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pickle.load(open(input_path + 'df_train.pkl', 'rb'))\n",
    "df_train.head()\n",
    "\n",
    "df_train_feat_offline = pickle.load(open(input_path + 'df_train_feat_offline.pkl', 'rb'))\n",
    "df_tem_feat = df_train_feat_offline[df_train_feat_offline.Date_received != -1]\n",
    "df_tem_feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "pickle.dump(df_test, open(input_path + 'df_test.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_offline, open(input_path + 'df_test_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_test_feat_online, open(input_path + 'df_test_feat_online.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(df_train, open(input_path + 'df_train.pkl', 'wb'))\n",
    "pickle.dump(df_train_feat_offline, open(input_path + 'df_train_feat_offline.pkl', 'wb'))\n",
    "pickle.dump(df_train_feat_online, open(input_path + 'df_train_feat_online.pkl', 'wb'))\n",
    "\n",
    "###数据加载###############################\n",
    "df_test = pickle.load(open(input_path + 'df_test.pkl', 'rb'))\n",
    "df_test_feat_offline = pickle.load(open(input_path + 'df_test_feat_offline.pkl', 'rb'))\n",
    "df_test_feat_online = pickle.load(open(input_path + 'df_test_feat_online.pkl', 'rb'))\n",
    "\n",
    "df_train = pickle.load(open(input_path + 'df_train.pkl', 'rb'))\n",
    "df_train_feat_offline = pickle.load(open(input_path + 'df_train_feat_offline.pkl', 'rb'))\n",
    "df_train_feat_online = pickle.load(open(input_path + 'df_train_feat_online.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ###转化为时间格式\n",
    "# on_train['Date_received'] = on_train.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_train['Date_received'] = off_train.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_test['Date_received'] = off_test.Date_received.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# on_train['Date'] = on_train.Date.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)   \n",
    "\n",
    "# off_train['Date'] = off_train.Date.apply(lambda x: \\\n",
    "#                                 datetime(int(str(x)[0: 4]), int(str(x)[4: 6]), int(str(x)[6: 8])) if x != -1 else -1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  2  3\n",
       "1  2  1  3\n",
       "2  7  8  3\n",
       "3  1  2  7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  4\n",
       "1  2  1\n",
       "2  7  8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>hahah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  hahah\n",
       "0  1      4\n",
       "1  2      1\n",
       "2  7      8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [[1,2,3],[2,1,3],[7,8,3],[1,2,7]]\n",
    "\n",
    "df = pd.DataFrame(a_list)\n",
    "df\n",
    "\n",
    "df.groupby([0])[[1]].sum().reset_index()\n",
    "\n",
    "grou = [0]\n",
    "stati = [1]\n",
    "name = ['hahah']\n",
    "df.groupby(grou)[stati].agg('sum').reset_index().rename(columns={stati[0]: name[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
